#Importing Needed Modules
import pandas as pd
import numpy as np
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import time
import matplotlib.pyplot as plt
import cv2
import seaborn as sns
sns.set_style('darkgrid')
import shutil
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, 
MaxPooling2D,BatchNormalization
from tensorflow.keras.optimizers import Adam, Adamax
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras import backend as K
import time
from tqdm import tqdm
from sklearn.metrics import f1_score
from IPython.display import YouTubeVideo
import sys
if not sys.warnoptions:
 import warnings
 warnings.simplefilter("ignore")
pd.set_option('display.max_columns', None) # or 1000
pd.set_option('display.max_rows', None) # or 1000
pd.set_option('display.max_colwidth', None) # or 199


#Detecting the images that throw errors and storing them in different 
lists
train_ewaste_dir=r'../input/waste-segregation-imagedataset/Dataset/train/non_biodegradable/ewaste'
valid_ewaste_dir=r'../input/waste-segregation-imagedataset/Dataset/val/non_biodegradable/ewaste'
bad_img_list=[]
for d in [train_ewaste_dir, valid_ewaste_dir]:
 flist=os.listdir(d)
 for f in flist:
 fpath=os.path.join(d,f)
 try:
 img=plt.imread(fpath)
 except:
 print (fpath)
 bad_img_list.append(fpath)
Output
../input/waste-segregation-imagedataset/Dataset/train/non_biodegradable/ewaste/00000006.jpg
../input/waste-segregation-imagedataset/Dataset/val/non_biodegradable/ewaste/00000261.jpg


#Read in train, test, and valid images and create train, test, and 
validation data frames using train, test and valid directories
def make_dataframes(train_dir, val_dir, bad_img_list):
 dirlist=[train_dir, val_dir]
 names=['train', 'valid']
 zipdir=zip(names, dirlist)
 for name,d in zipdir:
 filepaths=[]
 labels=[]
 major_classlist=sorted(os.listdir(d) ) #[biodegradable, non_biodegradabl] 
 for major_class in major_classlist:
 major_classpath=os.path.join(d, major_class) 
 class_list=sorted(os.listdir(major_classpath))
 for klass in class_list:
 classpath=os.path.join(major_classpath, klass)
 flist=sorted(os.listdir(classpath)) 
 desc=f'{name:5s}-{klass:25s}' 
 for f in tqdm(flist, ncols=130,desc=desc, unit='files', colour='blue'):
 fpath=os.path.join(classpath,f) 
 if fpath not in bad_img_list: # exclude bad image files from dataframes
 filepaths.append(fpath)
 labels.append(klass)
 Fseries=pd.Series(filepaths, name='filepaths')
 Lseries=pd.Series(labels, name='labels')
 df=pd.concat([Fseries, Lseries], axis=1)
 if name == 'valid':
 valid_df=df 
 else:
 pdf=df 
 train_df, test_df=train_test_split(pdf, train_size=.9, shuffle=True, random_state=123, 
stratify=pdf['labels'])
 classes=sorted(train_df['labels'].unique())
 class_count=len(classes)
 sample_df=train_df.sample(n=50, replace=False)
 # calculate the average image height and with
 ht=0
 wt=0
 count=0
 for i in range(len(sample_df)):
 fpath=sample_df['filepaths'].iloc[i]
 try:
 img=cv2.imread(fpath)
 h=img.shape[0]
 w=img.shape[1]
 wt +=w
 ht +=h
 count +=1
 except:
 pass
 have=int(ht/count)
 wave=int(wt/count)
 aspect_ratio=have/wave
 print('number of classes in processed dataset= ', class_count) 
 counts=list(train_df['labels'].value_counts()) 
 print('the maximum files in any class in train_df is ', max(counts), ' the minimum files in 
any class in train_df is ', min(counts))
 print('train_df length: ', len(train_df), ' test_df length: ', len(test_df), ' valid_df length: ', 
len(valid_df)) 
 print('average image height= ', have, ' average image width= ', wave, ' aspect ratio h/w= ', 
aspect_ratio) 
 return train_df, test_df, valid_df, classes, class_count
train_dir = r'../input/waste-segregation-image-dataset/Dataset/train'
val_dir=r'../input/waste-segregation-image-dataset/Dataset/val'
train_df, test_df, valid_df, classes, class_count=make_dataframes(train_dir, val_dir, 
bad_img_list)
Output
train-food_waste : 
100%|███████████████████████████████████████████████| 
10066/10066 [00:00<00:00, 476947.44files/s]
train-leaf_waste : 
100%|█████████████████████████████████████████████████| 
1179/1179 [00:00<00:00, 397610.71files/s]
train-paper_waste : 
100%|███████████████████████████████████████████████████| 
860/860 [00:00<00:00, 519530.67files/s]
train-wood_waste : 
100%|███████████████████████████████████████████████████| 
593/593 [00:00<00:00, 512829.33files/s]
train-ewaste : 
100%|███████████████████████████████████████████████████| 
180/180 [00:00<00:00, 473338.38files/s]
train-metal_cans : 
100%|███████████████████████████████████████████████████| 
670/670 [00:00<00:00, 536396.96files/s]
train-plastic_bags : 
100%|███████████████████████████████████████████████████| 
200/200 [00:00<00:00, 308745.23files/s]
train-plastic_bottles : 
100%|███████████████████████████████████████████████████| 
417/417 [00:00<00:00, 511560.33files/s]
valid-food_waste : 
100%|███████████████████████████████████████████████████| 
229/229 [00:00<00:00, 329614.14files/s]
valid-leaf_waste : 
100%|███████████████████████████████████████████████████| 
394/394 [00:00<00:00, 302610.47files/s]
valid-paper_waste : 
100%|███████████████████████████████████████████████████| 
212/212 [00:00<00:00, 479866.40files/s]
valid-wood_waste : 
100%|█████████████████████████████████████████████████████| 
59/59 [00:00<00:00, 229558.38files/s]
valid-ewaste : 
100%|█████████████████████████████████████████████████████| 
55/55 [00:00<00:00, 304336.04files/s]
valid-metal_cans : 
100%|█████████████████████████████████████████████████████| 
69/69 [00:00<00:00, 297132.42files/s]
valid-plastic_bags : 
100%|█████████████████████████████████████████████████████| 
53/53 [00:00<00:00, 300809.35files/s]
valid-plastic_bottles : 
100%|███████████████████████████████████████████████████| 
130/130 [00:00<00:00, 272085.59files/s]
number of classes in processed dataset= 8
the maximum files in any class in train_df is 9059 the minimum files in any class in train_df is 161
train_df length: 12747 test_df length: 1417 valid_df length: 1200
average image height= 512 average image width= 577 aspect ratio h/w= 0.8873483535528596


#Trim train_df so no class has more than max_samples images
def trim(df, max_samples, min_samples, column):
 df=df.copy()
 classes=df[column].unique()
 class_count=len(classes)
 length=len(df)
 print ('dataframe initially is of length ',length, ' with ', class_count, ' classes')
 groups=df.groupby(column) 
 trimmed_df = pd.DataFrame(columns = df.columns)
 groups=df.groupby(column)
 for label in df[column].unique(): 
 group=groups.get_group(label)
 count=len(group) 
 if count > max_samples:
 sampled_group=group.sample(n=max_samples, random_state=123,axis=0)
 trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)
 else:
 if count>=min_samples:
 sampled_group=group 
 trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)
 print('after trimming, the maximum samples in any class is now ',max_samples, ' and the 
minimum samples in any class is ', min_samples)
 classes=trimmed_df[column].unique()# return this in case some classes have less than 
min_samples
 class_count=len(classes) # return this in case some classes have less than min_samples
 length=len(trimmed_df)
 print ('the trimmed dataframe now is of length ',length, ' with ', class_count, ' classes')
 return trimmed_df, classes, class_count
max_samples=250
min_samples=161
column='labels'
train_df, classes, class_count=trim(train_df, max_samples, min_samples, column)
Output
dataframe initially is of length 12747 with 8 classes
after trimming, the maximum samples in any class is now 250 and the minimum samples in 
any class is 161
the trimmed dataframe now is of length 1841 with 8 classes



#Expand train_df rows with augmented images so each class has 250 
samples
def balance(df, n, working_dir, img_size):
 df=df.copy()
 print('Initial length of dataframe is ', len(df))
 aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images
 if os.path.isdir(aug_dir):# start with an empty directory
 shutil.rmtree(aug_dir)
 os.mkdir(aug_dir) 
 for label in df['labels'].unique(): 
 dir_path=os.path.join(aug_dir,label) 
 os.mkdir(dir_path) # make class directories within aug directory
 # create and store the augmented images 
 total=0
 gen=ImageDataGenerator(horizontal_flip=True, rotation_range=20, width_shift_range=.2,
 height_shift_range=.2, zoom_range=.2)
 groups=df.groupby('labels') # group by class
 for label in df['labels'].unique(): # for every class 
 group=groups.get_group(label) # a dataframe holding only rows with the specified label 
 sample_count=len(group) # determine how many samples there are in this class 
 if sample_count< n: # if the class has less than target number of images
 aug_img_count=0
 delta=n - sample_count # number of augmented images to create
 target_dir=os.path.join(aug_dir, label) # define where to write the images
 msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, 
str(delta))
 print(msg, '\r', end='') # prints over on the same line
 aug_gen=gen.flow_from_dataframe( group, x_col='filepaths', y_col=None, 
target_size=img_size,
 class_mode=None, batch_size=1, shuffle=False, 
 save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',
 save_format='jpg')
 while aug_img_count<delta:
 images=next(aug_gen) 
 aug_img_count += len(images)
 total +=aug_img_count
 print('Total Augmented images created= ', total)
 # create aug_df and merge with train_df to create composite training set ndf
 aug_fpaths=[]
 aug_labels=[]
 classlist=os.listdir(aug_dir)
 for klass in classlist:
 classpath=os.path.join(aug_dir, klass) 
 flist=os.listdir(classpath) 
 for f in flist: 
 fpath=os.path.join(classpath,f) 
 aug_fpaths.append(fpath)
 aug_labels.append(klass)
 Fseries=pd.Series(aug_fpaths, name='filepaths')
 Lseries=pd.Series(aug_labels, name='labels')
 aug_df=pd.concat([Fseries, Lseries], axis=1) 
 df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)
 print('Length of augmented dataframe is now ', len(df))
 return df 
n=250
working_dir=r'./'
img_size = (200,235)
train_df=balance(train_df, n, working_dir, img_size)
Output
Initial length of dataframe is 1841
Found 180 validated image filenames. for class plastic_bags creating 70 
augmented images 
Found 161 validated image filenames. for class ewaste creating 89 
augmented images 
Total Augmented images created= 159
Length of augmented dataframe is now 2000



#Create the train_gen, test_gen final_test_gen and valid_gen
def make_gens(batch_size, train_df, test_df, valid_df, img_size):
 trgen=ImageDataGenerator(horizontal_flip=True) 
 t_and_v_gen=ImageDataGenerator()
 msg='{0:70s} for train generator'.format(' ')
 print(msg, '\r', end='') # prints over on the same line
 train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', 
target_size=img_size,
 class_mode='categorical', color_mode='rgb', shuffle=True, 
batch_size=batch_size)
 msg='{0:70s} for valid generator'.format(' ')
 print(msg, '\r', end='') # prints over on the same line
 valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', 
target_size=img_size,
 class_mode='categorical', color_mode='rgb', shuffle=False, 
batch_size=batch_size)
 # for the test_gen we want to calculate the batch size and test steps such that batch_size X 
test_steps= number of samples in test set
 # this insures that we go through all the sample in the test set exactly once.
 length=len(test_df)
 test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and 
length/n<=80],reverse=True)[0] 
 test_steps=int(length/test_batch_size) 
 msg='{0:70s} for test generator'.format(' ')
 print(msg, '\r', end='') # prints over on the same line
 test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', 
target_size=img_size,
 class_mode='categorical', color_mode='rgb', shuffle=False, 
batch_size=test_batch_size)
 # from the generator we can get information we will need later
 classes=list(train_gen.class_indices.keys())
 class_indices=list(train_gen.class_indices.values())
 class_count=len(classes)
 labels=test_gen.labels
 print ( 'test batch size: ' ,test_batch_size, ' test steps: ', test_steps, ' number of classes : ', 
class_count)
 return train_gen, test_gen, valid_gen, test_batch_size, test_steps, classes
batch_size=30
train_gen, test_gen, valid_gen, test_batch_size, test_steps, classes=make_gens(batch_size, 
train_df, test_df, valid_df, img_size)
Output
Found 2000 validated image filenames belonging to 8 classes. for train generator 
Found 1200 validated image filenames belonging to 8 classes. for valid generator 
Found 1417 validated image filenames belonging to 8 classes. for test generator 
test batch size: 13 test steps: 109 number of classes : 8



#Create a function to show example training images
def show_image_samples(gen ):
 t_dict=gen.class_indices
 classes=list(t_dict.keys()) 
 images,labels=next(gen) # get a sample batch from the generator 
 plt.figure(figsize=(25, 25))
 length=len(labels)
 if length<25: #show maximum of 25 images
 r=length
 else:
 r=25
 for i in range(r): 
 plt.subplot(5, 5, i + 1)
 image=images[i] /255 
 plt.imshow(image)
 index=np.argmax(labels[i])
 class_name=classes[index]
 plt.title(class_name, color='blue', fontsize=18)
 plt.axis('off')
 plt.show()
 
show_image_samples(train_gen )
OUTPUT:
Image output


#Create a model using transfer learning with EfficientNetB3
def make_model(img_size, lr, mod_num=3): 
 img_shape=(img_size[0], img_size[1], 3)
 if mod_num == 0:
 base_model=tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, 
weights="imagenet",input_shape=img_shape, pooling='max')
 msg='Created EfficientNet B0 model'
 elif mod_num == 3:
 base_model=tf.keras.applications.efficientnet.EfficientNetB3(include_top=False, 
weights="imagenet",input_shape=img_shape, pooling='max') 
 msg='Created EfficientNet B3 model'
 elif mod_num == 5:
 base_model=tf.keras.applications.efficientnet.EfficientNetB5(include_top=False, 
weights="imagenet",input_shape=img_shape, pooling='max') 
 msg='Created EfficientNet B5 model'
 
 else:
 base_model=tf.keras.applications.efficientnet.EfficientNetB7(include_top=False, 
weights="imagenet",input_shape=img_shape, pooling='max')
 msg='Created EfficientNet B7 model' 
 
 base_model.trainable=True
 x=base_model.output
 x=BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)
 x = Dense(256, kernel_regularizer = regularizers.l2(l = 
0.016),activity_regularizer=regularizers.l1(0.006),
 bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)
 x=Dropout(rate=.4, seed=123)(x) 
 output=Dense(class_count, activation='softmax')(x)
 model=Model(inputs=base_model.input, outputs=output)
 model.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy', 
metrics=['accuracy']) 
 msg=msg + f' with initial learning rate set to {lr}'
 print_in_color(msg)
 return model
lr=.001
model=make_model(img_size, lr) # using B3 model by default
Output
Downloading data from https://storage.googleapis.com/kerasapplications/efficientnetb3_notop.h5
43941888/43941136 [==============================] - 0s 0us/step
43950080/43941136 [==============================] - 0s 0us/step
Created EfficientNet B3 model with initial learning rate set to 0.001



#Create a custom Keras callback to continue and optionally set LR or 
halt training
class LR_ASK(keras.callbacks.Callback):
 def _init_ (self, model, epochs, ask_epoch, dwell=True, factor=.4): # initialization of the 
callback
 super(LR_ASK, self)._init_()
 self.model=model 
 self.ask_epoch=ask_epoch
 self.epochs=epochs
 self.ask=True # if True query the user on a specified epoch
 self.lowest_vloss=np.inf
 self.lowest_aloss=np.inf
 self.best_weights=self.model.get_weights() # set best weights to model's initial weights
 self.best_epoch=1
 self.plist=[]
 self.alist=[]
 self.dwell= dwell
 self.factor=factor
 
 def get_list(self): # define a function to return the list of % validation change
 return self.plist, self.alist
 def on_train_begin(self, logs=None): # this runs on the beginning of training
 if self.ask_epoch == 0: 
 print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)
 self.ask_epoch=1
 if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs
 print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)
 self.ask=False # do not query the user
 if self.epochs == 1:
 self.ask=False # running only for 1 epoch so do not query user
 else:
 msg =f'Training will proceed until epoch {ask_epoch} then you will be asked to' 
 print_in_color(msg )
 msg='enter H to halt training or enter an integer for how many more epochs to run 
then be asked again'
 print_in_color(msg)
 if self.dwell:
 msg='learning rate will be automatically adjusted during training'
 print_in_color(msg, (0,255,0))
 self.start_time= time.time() # set the time at which training started
 
 def on_train_end(self, logs=None): # runs at the end of training 
 msg=f'loading model with weights from epoch {self.best_epoch}'
 print_in_color(msg, (0,255,255))
 model.set_weights(self.best_weights) # set the weights of the model to the best weights
 tr_duration=time.time() - self.start_time # determine how long the training cycle lasted 
 hours = tr_duration // 3600
 minutes = (tr_duration - (hours * 3600)) // 60
 seconds = tr_duration - ((hours * 3600) + (minutes * 60))
 msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, 
{seconds:4.2f} seconds)'
 print_in_color (msg) # print out training duration time
 
 def on_epoch_end(self, epoch, logs=None): # method runs on the end of each epoch
 vloss=logs.get('val_loss') # get the validation loss for this epoch
 aloss=logs.get('loss')
 if epoch >0:
 deltav = self.lowest_vloss- vloss 
 pimprov=(deltav/self.lowest_vloss) * 100 
 self.plist.append(pimprov)
 deltaa=self.lowest_aloss-aloss
 aimprov=(deltaa/self.lowest_aloss) * 100
 self.alist.append(aimprov)
 else:
 pimprov=0.0 
 aimprov=0.0
 if vloss< self.lowest_vloss:
 self.lowest_vloss=vloss
 self.best_weights=self.model.get_weights() # set best weights to model's initial 
weights
 self.best_epoch=epoch + 1 
 msg=f'\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % below lowest loss, 
saving weights from epoch {str(epoch + 1):3s} as best weights'
 print_in_color(msg, (0,255,0)) # green foreground
 else: # validation loss increased
 pimprov=abs(pimprov)
 msg=f'\n validation loss of {vloss:7.4f} is {pimprov:7.4f} % above lowest loss of 
{self.lowest_vloss:7.4f} keeping weights from epoch {str(self.best_epoch)} as best weights'
 print_in_color(msg, (255,255,0)) # yellow foreground
 if self.dwell: # if dwell is True when the validation loss increases the learning rate is 
automatically reduced and model weights are set to best weights
 lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current 
learning rate
 new_lr=lr * self.factor
 msg=f'learning rate was automatically adjusted from {lr:8.6f} to {new_lr:8.6f}, 
model weights set to best weights'
 print_in_color(msg) # cyan foreground
 tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in 
the optimizer
 model.set_weights(self.best_weights) # set the weights of the model to the best 
weights 
 
 if aloss< self.lowest_aloss:
 self.lowest_aloss=aloss 
 if self.ask: # are the conditions right to query the user?
 if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?
 msg='\n Enter H to end training or an integer for the number of additional epochs 
to run then ask again'
 print_in_color(msg) # cyan foreground
 ans=input()
 
 if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions
 msg=f'you entered {ans}, Training halted on epoch {epoch+1} due to user 
input\n'
 print_in_color(msg)
 self.model.stop_training = True # halt training
 else: # user wants to continue training
 self.ask_epoch += int(ans)
 if self.ask_epoch > self.epochs:
 print('\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', 
self.ask_epoch, flush =True)
 else:
 msg=f'you entered {ans} Training will continue to epoch {self.ask_epoch}'
 print_in_color(msg) # cyan foreground
 if self.dwell==False:
 lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the 
current learning rate
 msg=f'current LR is {lr:8.6f} hit enter to keep this LR or enter a new LR'
 print_in_color(msg) # cyan foreground
 ans=input(' ')
 if ans =='':
 msg=f'keeping current LR of {lr:7.5f}'
 print_in_color(msg) # cyan foreground
 else:
 new_lr=float(ans)
 tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the 
learning rate in the optimizer
 msg=f' changing LR to {ans}'
 print_in_color(msg) # cyan foreground


#Instantiate custom callback
epochs=40
ask_epoch=15
ask=LR_ASK(model, epochs, ask_epoch)
callbacks=[ask]
#Train the model
history=model.fit(x=train_gen, epochs=epochs, verbose=1, callbacks=callbacks, 
validation_data=valid_gen,validation_steps=None, shuffle=False, initial_epoch=0)

Output
Training will proceed until epoch 15 then you will be asked to
enter H to halt training or enter an integer for how many more epochs to run then be asked 
again
learning rate will be automatically adjusted during training
Epoch 1/40
67/67 [==============================] - 72s 761ms/step - loss: 7.7104 - accuracy: 
0.7950 - val_loss: 6.9910 - val_accuracy: 0.8825
validation loss of 6.9910 is 0.0000 % below lowest loss, saving weights from epoch 1 as 
best weights
Epoch 2/40
67/67 [==============================] - 40s 596ms/step - loss: 5.9159 - accuracy: 
0.9430 - val_loss: 5.4594 - val_accuracy: 0.9067
validation loss of 5.4594 is 21.9083 % below lowest loss, saving weights from epoch 2 as 
best weights
Epoch 3/40
67/67 [==============================] - 40s 597ms/step - loss: 4.8104 - accuracy: 
0.9750 - val_loss: 4.4979 - val_accuracy: 0.9100
validation loss of 4.4979 is 17.6119 % below lowest loss, saving weights from epoch 3 as 
best weights
continous......


#Define a function to plot the training data
def tr_plot(tr_data, start_epoch):
 #Plot the training and validation data
 tacc=tr_data.history['accuracy']
 tloss=tr_data.history['loss']
 vacc=tr_data.history['val_accuracy']
 vloss=tr_data.history['val_loss']
 Epoch_count=len(tacc)+ start_epoch
 Epochs=[]
 for i in range (start_epoch ,Epoch_count):
 Epochs.append(i+1) 
 index_loss=np.argmin(vloss)# this is the epoch with the lowest validation loss
 val_lowest=vloss[index_loss]
 index_acc=np.argmax(vacc)
 acc_highest=vacc[index_acc]
 plt.style.use('fivethirtyeight') 
 sc_label='best epoch= '+ str(index_loss+1 +start_epoch)
 vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)
 fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(25,10))
 axes[0].plot(Epochs,tloss, 'r', label='Training loss')
 axes[0].plot(Epochs,vloss,'g',label='Validation loss' )
 axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)
 axes[0].scatter(Epochs, tloss, s=100, c='red') 
 axes[0].set_title('Training and Validation Loss')
 axes[0].set_xlabel('Epochs', fontsize=18)
 axes[0].set_ylabel('Loss', fontsize=18)
 axes[0].legend()
 axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')
 axes[1].scatter(Epochs, tacc, s=100, c='red')
 axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')
 axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)
 axes[1].set_title('Training and Validation Accuracy')
 axes[1].set_xlabel('Epochs', fontsize=18)
 axes[1].set_ylabel('Accuracy', fontsize=18)
 axes[1].legend()
 plt.tight_layout 
 plt.show()
 return index_loss
 
loss_index=tr_plot(history,0)
Output:graph


#Make Predictions on the test set
def predictor(test_gen): 
 y_pred= []
 error_list=[]
 error_pred_list = []
 y_true=test_gen.labels
 classes=list(test_gen.class_indices.keys())
 class_count=len(classes)
 errors=0
 preds=model.predict(test_gen, verbose=1)
 tests=len(preds) 
 for i, p in enumerate(preds): 
 pred_index=np.argmax(p) 
 true_index=test_gen.labels[i] # labels are integer values 
 if pred_index != true_index: # a misclassification has occurred 
 errors=errors + 1
 file=test_gen.filenames[i]
 error_list.append(file)
 error_class=classes[pred_index]
 error_pred_list.append(error_class)
 y_pred.append(pred_index)
 
 acc=( 1-errors/tests) * 100
 msg=f'there were {errors} errors in {tests} tests for an accuracy of {acc:6.2f}'
 print_in_color(msg, (0,255,255), (100,100,100)) # cyan foreground
 ypred=np.array(y_pred)
 ytrue=np.array(y_true)
 f1score=f1_score(ytrue, ypred, average='weighted')* 100
 if class_count <=30:
 cm = confusion_matrix(ytrue, ypred )
 # plot the confusion matrix
 plt.figure(figsize=(12, 8))
 sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False) 
 plt.xticks(np.arange(class_count)+.5, classes, rotation=90)
 plt.yticks(np.arange(class_count)+.5, classes, rotation=0)
 plt.xlabel("Predicted")
 plt.ylabel("Actual")
 plt.title("Confusion Matrix")
 plt.show()
 clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create 
classification report
 print("Classification Report:\n----------------------\n", clr)
 return errors, tests, error_list, error_pred_list, f1score
errors, tests, error_list, error_pred_list, f1score =predictor(test_gen)
Output
109/109 [==============================] - 18s 144ms/step
there were 38 errors in 1417 tests for an accuracy of 97.32
confusion matrix

Classification Report:
----------------------
 precision recall f1-score support
 ewaste 0.8000 0.8889 0.8421 18
 food_waste 0.9990 0.9772 0.9880 1007
 leaf_waste 0.9832 0.9915 0.9873 118
 metal_cans 0.9143 0.9552 0.9343 67
 paper_waste 0.9091 0.9302 0.9195 86
 plastic_bags 0.7037 0.9500 0.8085 20
plastic_bottles 0.9091 0.9524 0.9302 42
 wood_waste 0.9219 1.0000 0.9593 59
 accuracy 0.9732 1417
 macro avg 0.8925 0.9557 0.9212 1417
 weighted avg 0.9756 0.9732 0.9739 1417



#Errors that were wrongly predicted
if len(error_list) > 0 and len(error_list)<50:
 print ('Below is a list of test files that were miss classified \n')
 print ('{0:^30s}{1:^30s}'.format('Test File', ' Predicted as'))
 sorted_list=sorted(error_list)
 for i in range(len(sorted_list)):
 fpath=sorted_list[i] 
 split=fpath.split('/') 
 f= split[6]
 print(f'{f:^30s}{error_pred_list[i]:^30s}')
Output
Below is a list of test files that were miss classified 
 Test File Predicted as 
 food_waste plastic_bags 
 food_waste plastic_bags 
 food_waste leaf_waste 
 food_waste leaf_waste 
 food_waste paper_waste 
 food_waste paper_waste 
 food_waste ewaste 
 food_waste plastic_bottles 
 food_waste paper_waste 
 food_waste wood_waste 
 food_waste metal_cans 
 food_waste metal_cans 
 food_waste metal_cans 
 food_waste metal_cans 
 food_waste plastic_bags 
........

#Save the Model
save_id='keras_model.h5'
model_save_loc=os.path.join(working_dir, save_id)
model.save(model_save_loc)


























